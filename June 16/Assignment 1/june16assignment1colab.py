# -*- coding: utf-8 -*-
"""June16Assignment1Colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OkXKXrb3x4zRL_H3snoIihbfTNEjggnK
"""

from pyspark.sql import SparkSession
spark=SparkSession.builder.appName("June16Assignment1").getOrCreate()
spark

course_enrollments_df=spark.read.csv("course_enrollments.csv",header=True,inferSchema=True)
course_enrollments_df.show()
course_details_df=spark.read.csv("course_details.csv",header=True,inferSchema=True)
course_details_df.show()

# Filtering and Transformation
# 3. Filter records where ProgressPercent < 50 .
course_enrollments_df.filter(course_enrollments_df.ProgressPercent<50).show()
# 4. Replace null ratings with average rating.
from pyspark.sql.functions import avg
average_rating = course_enrollments_df.select(avg("Rating")).collect()[0][0]
course_enrollments_df_filled = course_enrollments_df.fillna({"Rating": average_rating})
course_enrollments_df_filled.show()
# 5. Add column IsActive â†’ 1 if Status is Active, else 0.
from pyspark.sql import *
from pyspark.sql.functions import *
course_enrollments_df.withColumn("IsActive",when(course_enrollments_df.Status=="Active",1).otherwise(0)).show()

# Aggregations & Metrics
# 6. Find average progress by course.
course_enrollments_df.groupBy('CourseName').agg({'ProgressPercent': 'avg'}).show()
# 7. Get count of students in each course category.
course_enrollments_df.groupBy('Category').agg({'StudentName': 'count'}).show()
# 8. Identify the most enrolled course.
course_enrollments_df.groupBy('CourseName').agg({'StudentName': 'count'}).orderBy('count(StudentName)', ascending=False).show()

# 10. Join course_enrollments with course_details to include duration and instructor.
course_enrollments_df.join(course_details_df , course_enrollments_df.CourseName == course_details_df.CourseName).show()

# Window Functions
# 11. Rank students in each course based on ProgressPercent .
from pyspark.sql.window import Window
from pyspark.sql.functions import *
windowSpec = Window.partitionBy("CourseName").orderBy(desc("ProgressPercent"))
course_enrollments_df.withColumn("rank",rank().over(windowSpec)).show()
# 12. Get lead and lag of EnrollDate by Category.
from pyspark.sql.window import Window
from pyspark.sql.functions import *
windowSpec = Window.partitionBy("Category").orderBy("EnrollDate")

# Pivoting & Formatting
# 13. Pivot data to show total enrollments by Category and Status.
course_enrollments_df.groupBy('Category').pivot('Status').agg({'StudentName': 'count'}).show()
# 14. Extract year and month from EnrollDate .
from pyspark.sql.functions import *
course_enrollments_df.withColumn("year",year("EnrollDate")).withColumn("month",month("EnrollDate")).show()

# Cleaning and Deduplication
# 15. Drop rows where Status is null or empty.
course_enrollments_df.na.drop(subset=["Status"]).show()
# 16. Remove duplicate enrollments using dropDuplicates() .
course_enrollments_df.dropDuplicates().show()

# Export
# 17. Write the final cleaned DataFrame to:
# CSV (overwrite mode)
# JSON (overwrite mode)
# Parquet (snappy compression)
course_enrollments_df.write.mode("overwrite").csv("course_enrollments_csv")
course_enrollments_df.write.mode("overwrite").json("course_enrollments.json")
course_enrollments_df.write.mode("overwrite").parquet("course_enrollments.parquet",compression="snappy")