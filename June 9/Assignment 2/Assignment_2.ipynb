{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "wi1kjTLAHECT",
        "outputId": "b95502ee-9369-449b-a356-133a2c834019"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa429e3be10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://38a50beb8f11:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>June9Assignment2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName(\"June9Assignment2\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read all 3 files (CSV + JSON) using PySpark.\n",
        "df_employees=spark.read.csv(\"employees.csv\",header=True,inferSchema=True)\n",
        "df_employees.show()\n",
        "df_attendance=spark.read.csv(\"attendance.csv\",header=True,inferSchema=True)\n",
        "df_attendance.show()\n",
        "df_bonuses=spark.read.json(\"bonuses.json\")\n",
        "df_bonuses.show()\n",
        "#Show schemas and sample records.\n",
        "df_employees.printSchema()\n",
        "df_attendance.printSchema()\n",
        "df_bonuses.printSchema()\n",
        "#Count distinct departments.\n",
        "df_employees.select(\"department\").distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwFzL-1jICwi",
        "outputId": "80ebaaa8-7d51-40b7-9a3a-6971a6303436"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "|    2|2024-04-02|Present|\n",
            "|    3|2024-04-01|Present|\n",
            "|    3|2024-04-02|Present|\n",
            "|    4|2024-04-01| Absent|\n",
            "|    4|2024-04-02| Absent|\n",
            "|    5|2024-04-01|Present|\n",
            "|    5|2024-04-02|Present|\n",
            "+-----+----------+-------+\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "| 6000|    4|2023|\n",
            "| 4000|    5|2023|\n",
            "+-----+-----+----+\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import datediff, current_date, round\n",
        "\n",
        "#Add a column TenureYears using datediff() and round().\n",
        "df_employees = df_employees.withColumn(\"TenureYears\", round(datediff(current_date(), df_employees.JoinDate) / 365, 1))\n",
        "df_employees.show()\n",
        "#Calculate TotalCompensation = Salary + Bonus.\n",
        "df_employees_with_bonus = df_employees.join(df_bonuses, on=\"EmpID\", how=\"left\")\n",
        "df_employees= df_employees_with_bonus.withColumn(\"TotalCompensation\", df_employees_with_bonus.Salary + df_employees_with_bonus.Bonus)\n",
        "df_employees.show()\n",
        "#Filter employees with more than 2 years in the company.\n",
        "df_employees.filter(df_employees_with_bonus.TenureYears > 2).show()\n",
        "#Show employees who report to a manager (ManagerID is not null).\n",
        "df_employees.filter(df_employees_with_bonus.ManagerID.isNotNull()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-dssthYJfrM",
        "outputId": "f85d57a7-c92b-47ae-e3e5-b69d52a271f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average salary per department.\n",
        "df_employees.groupBy(\"Department\").agg(F.avg(\"Salary\")).show()\n",
        "#Number of employees under each manager.\n",
        "df_employees.groupBy(\"ManagerID\").count().show()\n",
        "#Count of absences per employee.\n",
        "df_attendance.groupBy(\"EmpID\").agg(F.count(F.when(df_attendance.Status == \"Absent\", 1).otherwise(None)).alias(\"AbsentCount\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr_M9QwlLBIZ",
        "outputId": "7431684b-5de2-41a1-e11f-ba88a4b69d1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "| Department|avg(Salary)|\n",
            "+-----------+-----------+\n",
            "|Engineering|    77500.0|\n",
            "|         HR|    52500.0|\n",
            "|  Marketing|    60000.0|\n",
            "+-----------+-----------+\n",
            "\n",
            "+---------+-----+\n",
            "|ManagerID|count|\n",
            "+---------+-----+\n",
            "|     NULL|    1|\n",
            "|        1|    4|\n",
            "+---------+-----+\n",
            "\n",
            "+-----+-----------+\n",
            "|EmpID|AbsentCount|\n",
            "+-----+-----------+\n",
            "|    1|          0|\n",
            "|    3|          0|\n",
            "|    5|          0|\n",
            "|    4|          2|\n",
            "|    2|          1|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Join employees and attendance → Get attendance % (Present days / Total days).\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import round\n",
        "df_employees_with_attendance = df_employees.join(df_attendance, on=\"EmpID\", how=\"left\")\n",
        "df_employees_with_attendance = df_employees_with_attendance.groupBy(\"EmpID\").agg(F.count(F.when(df_attendance.Status == \"Present\", 1)).alias(\"PresentDays\"),F.count(F.when(df_attendance.Status.isNotNull(), 1)).alias(\"TotalDays\"))\n",
        "df_employees_with_attendance = df_employees_with_attendance.withColumn(\"AttendancePercentage\", round((F.col(\"PresentDays\") / F.col(\"TotalDays\")) * 100, 2))\n",
        "df_employees_with_attendance.show()\n",
        "\n",
        "#Join employees and bonuses → Show top 3 employees by TotalCompensation.\n",
        "df_bonuses_renamed = df_bonuses.withColumnRenamed(\"Bonus\", \"Bonus_renamed\")\n",
        "df_employees_with_bonuses = df_employees.join(df_bonuses_renamed, on=\"EmpID\", how=\"left\")\n",
        "df_employees_with_bonuses = df_employees_with_bonuses.withColumn(\"TotalCompensation\", df_employees_with_bonuses.Salary + df_employees_with_bonuses[\"Bonus_renamed\"])\n",
        "df_employees_with_bonuses.orderBy(F.desc(\"TotalCompensation\")).limit(3).show()\n",
        "#Multi-level join: employees + bonuses + attendance.\n",
        "df_employees_with_bonuses_and_attendance = df_employees_with_bonuses.join(df_employees_with_attendance, on=\"EmpID\", how=\"left\")\n",
        "df_employees_with_bonuses_and_attendance.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsYPNjnMLfqe",
        "outputId": "7850c5a9-6e2f-4215-d449-ede26ba72b4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+---------+--------------------+\n",
            "|EmpID|PresentDays|TotalDays|AttendancePercentage|\n",
            "+-----+-----------+---------+--------------------+\n",
            "|    1|          2|        2|               100.0|\n",
            "|    3|          2|        2|               100.0|\n",
            "|    5|          2|        2|               100.0|\n",
            "|    4|          0|        2|                 0.0|\n",
            "|    2|          1|        2|                50.0|\n",
            "+-----+-----------+---------+--------------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-------------+----+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|Bonus_renamed|Year|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-------------+----+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|         7000|2023|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|         6500|2023|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|         6000|2023|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-------------+----+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-------------+----+-----------+---------+--------------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|Bonus_renamed|Year|PresentDays|TotalDays|AttendancePercentage|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-------------+----+-----------+---------+--------------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|         5000|2023|          2|        2|               100.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|         7000|2023|          1|        2|                50.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|         6500|2023|          2|        2|               100.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|         6000|2023|          0|        2|                 0.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|         4000|2023|          2|        2|               100.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-------------+----+-----------+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract year and month from JoinDate.\n",
        "from pyspark.sql.functions import year,month,col\n",
        "df_employees = df_employees.withColumn(\"JoinYear\", year(df_employees.JoinDate)).withColumn(\"JoinMonth\", month(df_employees.JoinDate))\n",
        "df_employees.show()\n",
        "#Mask employee names using regex.\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "import re\n",
        "\n",
        "def mask_name(name):\n",
        "    name_parts = name.split(' ')\n",
        "    if len(name_parts) == 2:\n",
        "        first_name, last_name = name_parts\n",
        "        masked_first_name = first_name[0] + '*' * (len(first_name) - 1)\n",
        "        masked_last_name = last_name[0] + '*' * (len(last_name) - 1)\n",
        "        return f\"{masked_first_name} {masked_last_name}\"\n",
        "    elif len(name_parts) == 1:\n",
        "        return name[0] + '*' * (len(name) - 1)\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "mask_name_udf = udf(mask_name, StringType())\n",
        "customers_df = df_employees.withColumn(\"Name\", mask_name_udf(col(\"Name\")))\n",
        "customers_df.show()\n",
        "\n",
        "#Use substring() to create EmpCode like \"EMP001\".\n",
        "from pyspark.sql.functions import col, lpad,concat,lit\n",
        "df_employees_with_code = df_employees.withColumn(\"EmpCode\",lpad(\"EmpID\", 3, \"0\"))\n",
        "df_employees_with_code = df_employees_with_code.withColumn(\"EmpCode\",concat(lit(\"EMP\"), col(\"EmpCode\")))\n",
        "df_employees_with_code.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLPcGMFYNeMP",
        "outputId": "4e16e91b-78ae-475f-f79f-5aade8dca235"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|    2021|        5|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|    1| A****|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|    2021|        5|\n",
            "|    2|   R**|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3|\n",
            "|    3|S*****|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|\n",
            "|    4| A****|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11|\n",
            "|    5| N****|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+-------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|            60000|    2021|        5| EMP001|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3| EMP002|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7| EMP003|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11| EMP004|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1| EMP005|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use when/otherwise to label performance:\n",
        "#“High” if Bonus > 6000\n",
        "#“Medium” if 4000–6000\n",
        "#“Low” otherwise\n",
        "from pyspark.sql.functions import when\n",
        "df_employees_with_performance = df_employees.withColumn(\"Performance\", when(df_employees.Bonus > 6000, \"High\").when((df_employees.Bonus >= 4000) & (df_employees.Bonus <= 6000), \"Medium\").otherwise(\"Low\"))\n",
        "df_employees_with_performance.show()\n",
        "#Handle missing ManagerID using fillna(\"No Manager\").\n",
        "df_employees = df_employees.fillna({\"ManagerID\": -1})\n",
        "df_employees.show()\n",
        "df_employees = df_employees.fillna({\"ManagerID\": \"No Manager\"})\n",
        "df_employees.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AsdwhDuOiZN",
        "outputId": "e4891255-dd83-41b6-d635-ce48bf6e91bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|Performance|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|       -1|        4.1| 5000|2023|            60000|    2021|        5|     Medium|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3|       High|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|       High|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11|     Medium|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1|     Medium|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+-----------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|       -1|        4.1| 5000|2023|            60000|    2021|        5|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|       -1|        4.1| 5000|2023|            60000|    2021|        5|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create and use database hr.\n",
        "spark.sql(\"create database if not exists hr\")\n",
        "spark.sql(\"use hr\")\n",
        "# save all dataframes as tables: employees, attendance, bonuses.\n",
        "df_employees.write.mode('overwrite').saveAsTable(\"employees\")\n",
        "df_attendance.write.mode('overwrite').saveAsTable(\"attendance\")\n",
        "df_bonuses.write.mode('overwrite').saveAsTable(\"bonuses\")\n",
        "# write sql queries:\n",
        "# top paid employee in each department.\n",
        "spark.sql(\"\"\"select Department, max(Salary) as max_salary from employees group by Department\"\"\").show()\n",
        "# attendance rate by department.\n",
        "spark.sql(\"\"\"select Department, count(case when status = 'Present' then 1 end) / count(*) as attendance_rate from employees e join attendance a on e.EmpID = a.EmpID group by Department\"\"\").show()\n",
        "# employees joined after 2021 with salary > 70,000.\n",
        "spark.sql(\"\"\"select * from employees where JoinDate > '2021-01-01' and Salary > 70000\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chkUupSAPdcw",
        "outputId": "9d5baf99-0179-4d28-8c82-bdf92839d4bd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+\n",
            "| Department|max_salary|\n",
            "+-----------+----------+\n",
            "|Engineering|     80000|\n",
            "|         HR|     55000|\n",
            "|  Marketing|     60000|\n",
            "+-----------+----------+\n",
            "\n",
            "+-----------+---------------+\n",
            "| Department|attendance_rate|\n",
            "+-----------+---------------+\n",
            "|Engineering|           0.75|\n",
            "|         HR|            1.0|\n",
            "|  Marketing|            0.0|\n",
            "+-----------+---------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a UDF to classify department as \"Tech\" vs \"Non-Tech\".\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def classify_department(department):\n",
        "    if department in [\"Engineering\"]:\n",
        "        return \"Tech\"\n",
        "    else:\n",
        "        return \"Non-Tech\"\n",
        "\n",
        "classify_department_udf = udf(classify_department, StringType())\n",
        "df_employees = df_employees.withColumn(\"DepartmentType\", classify_department_udf(df_employees.Department))\n",
        "df_employees.show()\n",
        "#Create a view emp_attendance_summary.\n",
        "df_employees.createOrReplaceTempView(\"emp_attendance_summary\")\n",
        "#Save it as Parquet partitioned by Department.\n",
        "df_employees.write.mode('overwrite').partitionBy(\"Department\").parquet(\"emp_attendance_summary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzwM4xkhRhE3",
        "outputId": "3340b7bc-5def-463b-b326-92a6ef42f39a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+--------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|JoinYear|JoinMonth|DepartmentType|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+--------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|       -1|        4.1| 5000|2023|            60000|    2021|        5|      Non-Tech|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|    2020|        3|          Tech|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|    2022|        7|          Tech|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|    2019|       11|      Non-Tech|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|            54000|    2023|        1|      Non-Tech|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+--------+---------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}