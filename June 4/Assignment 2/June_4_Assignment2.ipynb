{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "hd1qapKPKcDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "509daf71-3f70-4941-e375-376bb5b47821"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7b897a0fe490>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c8364b215228:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PracticeProject</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "spark = SparkSession.builder.appName(\"PracticeProject\").enableHiveSupport().getOrCreate()\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customers Data\n",
        "customers_data = [\n",
        "(101, 'Ali', 'ali@gmail.com', 'Mumbai', '2022-05-10'),\n",
        "(102, 'Neha', 'neha@yahoo.com', 'Delhi', '2023-01-15'),\n",
        "(103, 'Ravi', 'ravi@hotmail.com', 'Bangalore', '2021-11-01'),\n",
        "(104, 'Sneha', 'sneha@outlook.com', 'Hyderabad', '2020-07-22'),\n",
        "(105, 'Amit', 'amit@gmail.com', 'Chennai', '2023-03-10'),\n",
        "]\n",
        "orders_data = [\n",
        "(1, 101, 'Laptop', 'Electronics', 2, 50000.0, '2024-01-10'),\n",
        "(2, 101, 'Mouse', 'Electronics', 1, 1200.0, '2024-01-15'),\n",
        "(3, 102, 'Tablet', 'Electronics', 1, 20000.0, '2024-02-01'),\n",
        "(4, 103, 'Bookshelf', 'Furniture', 1, 3500.0, '2024-02-10'),\n",
        "(5, 104, 'Mixer', 'Appliances', 1, 5000.0, '2024-02-15'),\n",
        "(6, 105, 'Notebook', 'Stationery', 5, 500.0, '2024-03-01'),\n",
        "(7, 102, 'Phone', 'Electronics', 1, 30000.0, '2024-03-02'),\n",
        "]\n",
        "\n",
        "# Write as tables\n",
        "customers_df = spark.createDataFrame(customers_data, [\"CustomerID\", \"Name\", \"Email\",\n",
        "\"City\", \"SignupDate\"])\n",
        "orders_df = spark.createDataFrame(orders_data, [\"OrderID\", \"CustomerID\", \"Product\",\n",
        "\"Category\", \"Quantity\", \"Price\", \"OrderDate\"])\n",
        "spark.sql(\"create database if not exists sales\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y59skLvcXu0",
        "outputId": "be053bd1-825e-4e60-b246-97a2bdd2eb6e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Add a column TotalAmount = Price * Quantity to the orders_df\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "orders_df.show()\n",
        "#2. Filter all orders with TotalAmount > 10000 .\n",
        "orders_df.filter(col(\"TotalAmount\") > 10000).show()\n",
        "#3. Standardize the City field in customers_df (e.g., lowercase).\n",
        "from pyspark.sql.functions import lower\n",
        "customers_df = customers_df.withColumn(\"City\", lower(col(\"City\")))\n",
        "customers_df.show()\n",
        "#4. Extract year from OrderDate and add a new column OrderYear .\n",
        "orders_df = orders_df.withColumn(\"OrderYear\", year(col(\"OrderDate\")))\n",
        "orders_df.show()\n",
        "#5. Fill null values in any column of your choice with defaults.\n",
        "orders_df = orders_df.fillna({\"Category\": \"Unknown\"})\n",
        "orders_df.show()\n",
        "#6. Use when/otherwise to categorize orders:\n",
        "#<5000 : \"Low\"\n",
        "#5000-20000 : \"Medium\"\n",
        "#>20000 : \"High\"\n",
        "from pyspark.sql.functions import when,col\n",
        "orders_df = orders_df.withColumn(\"Category product\", when(col(\"TotalAmount\") < 5000, \"Low\").otherwise(when(col(\"TotalAmount\") < 20000, \"Medium\").otherwise(\"High\")))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRByoxVRK3qB",
        "outputId": "77298327-2e58-421d-9272-a6065f20b7c8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|Category product|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|            High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|             Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|            High|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|             Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|          Medium|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|             Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|            High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")\n",
        "\n",
        "#7. Run a SQL query to list all orders made by “Ali”.\n",
        "spark.sql(\"select * from sales.orders where customerid = (select customerid from sales.customers where name = 'Ali')\").show()\n",
        "\n",
        "#8. Get total spending by each customer using SQL.\n",
        "spark.sql(\"\"\"select c.Name, sum(o.Quantity * o.Price) as TotalSpending from sales.customers c join sales.orders o on c.CustomerID = o.CustomerID group by c.Name\"\"\").show()\n",
        "\n",
        "#9. Find out which category made the highest total revenue.\n",
        "spark.sql(\"select category, sum(quantity * price) as totalrevenue from sales.orders group by category order by totalrevenue desc limit 1\").show()\n",
        "\n",
        "#10. Create a view customer_orders showing CustomerName, Product, TotalAmount .\n",
        "spark.sql(\"create or replace view sales.customer_orders as select c.Name as CustomerName, o.Product, (o.Quantity * o.Price) as TotalAmount from sales.customers c join sales.orders o on c.CustomerID = o.CustomerID\")\n",
        "\n",
        "#11. Query the view for products ordered after Feb 2024.\n",
        "spark.sql(\"select * from sales.orders where orderdate > '2024-02-01'\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGCrWnHDSlLk",
        "outputId": "9e674c59-b249-4d16-c29b-66a1a8226b0f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|Category product|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|            High|\n",
            "|      2|       101|  Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|             Low|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "\n",
            "+-----+-------------+\n",
            "| Name|TotalSpending|\n",
            "+-----+-------------+\n",
            "| Ravi|       3500.0|\n",
            "|Sneha|       5000.0|\n",
            "| Amit|       2500.0|\n",
            "| Neha|      50000.0|\n",
            "|  Ali|     101200.0|\n",
            "+-----+-------------+\n",
            "\n",
            "+-----------+------------+\n",
            "|   category|totalrevenue|\n",
            "+-----------+------------+\n",
            "|Electronics|    151200.0|\n",
            "+-----------+------------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|Category product|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|             Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|          Medium|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|             Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|            High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Create a Global Temp View from customers_df , then query it using:\n",
        "#SELECT * FROM global_temp.customers WHERE City = 'Mumbai';\n",
        "customers_df.createOrReplaceGlobalTempView(\"customers\")\n",
        "spark.sql(\"select * from global_temp.customers where City = 'mumbai'\").show()\n",
        "#13. Save the transformed orders_df (with TotalAmount) to a Parquet file.\n",
        "orders_df.write.mode(\"overwrite\").parquet(\"orders.parquet\")\n",
        "#14. Read back the Parquet file and count how many orders are in it.\n",
        "orders_df_parquet = spark.read.parquet(\"orders.parquet\")\n",
        "orders_df_parquet.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QrJPLAgTxUs",
        "outputId": "a6260fd4-30d1-49e3-d216-4f10357113cd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-------------+------+----------+\n",
            "|CustomerID|Name|        Email|  City|SignupDate|\n",
            "+----------+----+-------------+------+----------+\n",
            "|       101| Ali|ali@gmail.com|mumbai|2022-05-10|\n",
            "+----------+----+-------------+------+----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Write a UDF that masks emails like:\n",
        "#ali@gmail.com → a***@gmail.com .\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "def mask_email(email):\n",
        "    parts = email.split('@')\n",
        "    if len(parts) == 2:\n",
        "        username, domain = parts\n",
        "        masked_username = username[0] + '*' * (len(username) - 2) + username[-1]\n",
        "        return f\"{masked_username}@{domain}\"\n",
        "    else:\n",
        "        return email\n",
        "mask_email_udf = udf(mask_email, StringType())\n",
        "customers_df = customers_df.withColumn(\"Email\", mask_email_udf(col(\"Email\")))\n",
        "customers_df.show()\n",
        "#16. Use concat_ws() to create a full label like:\n",
        "#'Ali from Mumbai'.\n",
        "from pyspark.sql.functions import concat_ws\n",
        "customers_df = customers_df.withColumn(\"FullLabel\", concat_ws(\" from \", col(\"Name\"), col(\"City\")))\n",
        "customers_df.show()\n",
        "#17. Use regexp_replace() to remove special characters from product names.\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "orders_df = orders_df.withColumn(\"Product\", regexp_replace(col(\"Product\"), \"[^a-zA-Z0-9 ]\", \"\"))\n",
        "orders_df.show()\n",
        "#18. Use to_date() and datediff() to calculate customer age in days (from SignupDate to today).\n",
        "from pyspark.sql.functions import datediff, to_date, current_date\n",
        "customers_df = customers_df.withColumn(\"AgeInDays\", datediff(to_date(current_date()), to_date(col(\"SignupDate\"))))\n",
        "customers_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c88M9pqlXXpo",
        "outputId": "9d23e172-5981-4ceb-869d-722dadd2ed45"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    a*i@gmail.com|   mumbai|2022-05-10|\n",
            "|       102| Neha|   n**a@yahoo.com|    delhi|2023-01-15|\n",
            "|       103| Ravi| r**i@hotmail.com|bangalore|2021-11-01|\n",
            "|       104|Sneha|s***a@outlook.com|hyderabad|2020-07-22|\n",
            "|       105| Amit|   a**t@gmail.com|  chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+--------------------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|           FullLabel|\n",
            "+----------+-----+-----------------+---------+----------+--------------------+\n",
            "|       101|  Ali|    a*i@gmail.com|   mumbai|2022-05-10|     Ali from mumbai|\n",
            "|       102| Neha|   n**a@yahoo.com|    delhi|2023-01-15|     Neha from delhi|\n",
            "|       103| Ravi| r**i@hotmail.com|bangalore|2021-11-01| Ravi from bangalore|\n",
            "|       104|Sneha|s***a@outlook.com|hyderabad|2020-07-22|Sneha from hyderabad|\n",
            "|       105| Amit|   a**t@gmail.com|  chennai|2023-03-10|   Amit from chennai|\n",
            "+----------+-----+-----------------+---------+----------+--------------------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|Category product|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|            High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|             Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|            High|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|             Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|          Medium|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|             Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|            High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+----------------+\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+--------------------+---------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|           FullLabel|AgeInDays|\n",
            "+----------+-----+-----------------+---------+----------+--------------------+---------+\n",
            "|       101|  Ali|    a*i@gmail.com|   mumbai|2022-05-10|     Ali from mumbai|     1121|\n",
            "|       102| Neha|   n**a@yahoo.com|    delhi|2023-01-15|     Neha from delhi|      871|\n",
            "|       103| Ravi| r**i@hotmail.com|bangalore|2021-11-01| Ravi from bangalore|     1311|\n",
            "|       104|Sneha|s***a@outlook.com|hyderabad|2020-07-22|Sneha from hyderabad|     1778|\n",
            "|       105| Amit|   a**t@gmail.com|  chennai|2023-03-10|   Amit from chennai|      817|\n",
            "+----------+-----+-----------------+---------+----------+--------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "iOV4eiC1ce4R"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}