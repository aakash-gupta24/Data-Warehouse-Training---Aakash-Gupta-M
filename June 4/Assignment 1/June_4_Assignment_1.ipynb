{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "un68AjA6atrx",
        "outputId": "ae6613b5-fd61-4802-d6e4-d9390a1876c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7df64915d050>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://46c5f24b03b4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "spark=SparkSession.builder.appName(\"Colab PySpark Setup\").getOrCreate()\n",
        "\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Create a new database named sales_db.\n",
        "spark.sql(\"\"\"create database if not exists sales_db\"\"\")\n",
        "#2. Set the current database to sales_db.\n",
        "spark.sql(\"\"\"use sales_db\"\"\")\n",
        "#3. Create a table product_sales with columns:\n",
        "#\"\"\"ProductID (INT)\n",
        "# ProductName (STRING)\n",
        "# Category (STRING)\n",
        "# Price (DOUBLE)\n",
        "# Quantity (INT)\n",
        "# SaleDate (DATE)\n",
        "#\"\"\"\n",
        "spark.sql(\"\"\"create table if not exists product_sales(productid int,\n",
        "productname string, category string,\n",
        "price double, quantity int, saledate date) using parquet\"\"\")\n",
        "#4. Insert at least 5 rows into product_sales.\n",
        "spark.sql(\"\"\"insert into product_sales values\n",
        "  (201, 'Smartphone', 'Electronics', 45000.00, 3, date '2024-06-01'),\n",
        "  (202, 'Office Chair', 'Furniture', 3000.00, 2, date '2024-06-02'),\n",
        "  (203, 'Notebook', 'Stationery', 50.00, 10, date '2024-06-03'),\n",
        "  (204, 'Headphones', 'Electronics', 1500.00, 4, date '2024-06-04'),\n",
        "  (205, 'Water Bottle', 'Accessories', 250.00, 6, date '2024-06-05');\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJvff6Fea1yj",
        "outputId": "556bc9d5-d557-435c-8ceb-9ff32beb6091"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Select all records from product_sales.\n",
        "spark.sql(\"\"\"select * from product_sales\"\"\").show()\n",
        "#6. Retrieve products where price is above 500.\n",
        "spark.sql(\"\"\"select * from product_sales where Price > 500\"\"\").show()\n",
        "#7. Calculate total sale amount (Price * Quantity) for each product.\n",
        "spark.sql(\"\"\"select ProductName, Price * Quantity as TotalSaleAmount from product_sales\"\"\").show()\n",
        "#8. Find the number of products sold in each Category.\n",
        "spark.sql(\"\"\"select Category, count(ProductID) as NumberOfProductsSold from product_sales group by Category\"\"\").show()\n",
        "#9. Sort products by total sales in descending order.\n",
        "spark.sql(\"\"\"select ProductName, Price * Quantity as TotalSaleAmount from product_sales order by TotalSaleAmount desc\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU4zcYskdVJr",
        "outputId": "6c03f84a-d149-4dfa-82b1-e78e5a815e77"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+-----------+-------+--------+----------+\n",
            "|productid| productname|   category|  price|quantity|  saledate|\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "|      203|    Notebook| Stationery|   50.0|      10|2024-06-03|\n",
            "|      204|  Headphones|Electronics| 1500.0|       4|2024-06-04|\n",
            "|      205|Water Bottle|Accessories|  250.0|       6|2024-06-05|\n",
            "|      201|  Smartphone|Electronics|45000.0|       3|2024-06-01|\n",
            "|      202|Office Chair|  Furniture| 3000.0|       2|2024-06-02|\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "|productid| productname|   category|  price|quantity|  saledate|\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "|      204|  Headphones|Electronics| 1500.0|       4|2024-06-04|\n",
            "|      201|  Smartphone|Electronics|45000.0|       3|2024-06-01|\n",
            "|      202|Office Chair|  Furniture| 3000.0|       2|2024-06-02|\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "\n",
            "+------------+---------------+\n",
            "| ProductName|TotalSaleAmount|\n",
            "+------------+---------------+\n",
            "|    Notebook|          500.0|\n",
            "|  Headphones|         6000.0|\n",
            "|Water Bottle|         1500.0|\n",
            "|  Smartphone|       135000.0|\n",
            "|Office Chair|         6000.0|\n",
            "+------------+---------------+\n",
            "\n",
            "+-----------+--------------------+\n",
            "|   Category|NumberOfProductsSold|\n",
            "+-----------+--------------------+\n",
            "| Stationery|                   1|\n",
            "|Electronics|                   2|\n",
            "|Accessories|                   1|\n",
            "|  Furniture|                   1|\n",
            "+-----------+--------------------+\n",
            "\n",
            "+------------+---------------+\n",
            "| ProductName|TotalSaleAmount|\n",
            "+------------+---------------+\n",
            "|  Smartphone|       135000.0|\n",
            "|  Headphones|         6000.0|\n",
            "|Office Chair|         6000.0|\n",
            "|Water Bottle|         1500.0|\n",
            "|    Notebook|          500.0|\n",
            "+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Create a PySpark DataFrame with dummy product data.\n",
        "from pyspark.sql import Row\n",
        "data = [\n",
        "    Row(206, 'Laptop', 'Electronics', 75000.0, 2, '2024-06-06'),\n",
        "    Row(207, 'Bookshelf', 'Furniture', 5200.0, 1, '2024-06-07'),\n",
        "    Row(208, 'Pen Set', 'Stationery', 120.0, 15, '2024-06-08'),\n",
        "    Row(209, 'Bluetooth Speaker', 'Electronics', 3200.0, 3, '2024-06-09'),\n",
        "    Row(210, 'Coffee Mug', 'Accessories', 350.0, 5, '2024-06-10'),\n",
        "]\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, [\"ProductID\", \"ProductName\", \"Category\", \"Price\", \"Quantity\", \"SaleDate\"])\n",
        "\n",
        "#11. Register it as a temporary view called temp_orders.\n",
        "# Register temporary view\n",
        "df.createOrReplaceTempView(\"temp_orders\")\n",
        "\n",
        "#12. Run a SQL query to filter temp_orders where quantity > 1.\n",
        "spark.sql(\"select * from product_sales where quantity>1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC4IWZBXdi4S",
        "outputId": "e0ac6bb2-a9e2-4abe-c7d7-b53db449aed6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+-----------+-------+--------+----------+\n",
            "|productid| productname|   category|  price|quantity|  saledate|\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "|      203|    Notebook| Stationery|   50.0|      10|2024-06-03|\n",
            "|      204|  Headphones|Electronics| 1500.0|       4|2024-06-04|\n",
            "|      205|Water Bottle|Accessories|  250.0|       6|2024-06-05|\n",
            "|      201|  Smartphone|Electronics|45000.0|       3|2024-06-01|\n",
            "|      202|Office Chair|  Furniture| 3000.0|       2|2024-06-02|\n",
            "+---------+------------+-----------+-------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Create a global temp view from a PySpark DataFrame named global_orders.\n",
        "df.createOrReplaceGlobalTempView(\"global_orders\")\n",
        "#14. Run a SQL query on the global view from another notebook cell/session.\n",
        "spark.sql(\"select * from global_temp.global_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0MSIHSJeNid",
        "outputId": "b31b69db-6fcc-4595-ddea-205ae431dc8f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+-----------+-------+--------+----------+\n",
            "|ProductID|      ProductName|   Category|  Price|Quantity|  SaleDate|\n",
            "+---------+-----------------+-----------+-------+--------+----------+\n",
            "|      206|           Laptop|Electronics|75000.0|       2|2024-06-06|\n",
            "|      207|        Bookshelf|  Furniture| 5200.0|       1|2024-06-07|\n",
            "|      208|          Pen Set| Stationery|  120.0|      15|2024-06-08|\n",
            "|      209|Bluetooth Speaker|Electronics| 3200.0|       3|2024-06-09|\n",
            "|      210|       Coffee Mug|Accessories|  350.0|       5|2024-06-10|\n",
            "+---------+-----------------+-----------+-------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15. Create a second table customer_details with:\n",
        "#CustomerID, Name, Gender, City, SignupDate\n",
        "spark.sql(\"\"\"create table if not exists customer_details(CustomerID INT,\n",
        "Name STRING, Gender STRING, City STRING, SignupDate DATE) using parquet\"\"\")\n",
        "#16. Insert at least 3 records into customer_details.\n",
        "spark.sql(\"\"\"\n",
        "insert into customer_details values\n",
        "  (201, 'Alice Sharma', 'Female', 'Mumbai', DATE '2024-05-12'),\n",
        "  (202, 'Ravi Verma', 'Male', 'Delhi', DATE '2024-05-15'),\n",
        "  (203, 'Priya Singh', 'Female', 'Bangalore', DATE '2024-05-20')\n",
        "\"\"\")\n",
        "#17. Write a SQL join between product_sales and customer_details based on\n",
        "#ProductID = CustomerID (simulate a match).\n",
        "spark.sql(\"\"\"\n",
        "select p.*, c.Name, c.Gender, c.City, c.SignupDate\n",
        "from product_sales p\n",
        "join customer_details c ON p.ProductID = c.CustomerID\n",
        "\"\"\").show()\n",
        "\n",
        "#18. List customers who bought more than 2 products.\n",
        "spark.sql(\"\"\"\n",
        "select c.Name, SUM(p.Quantity) AS TotalQuantity\n",
        "from customer_details c\n",
        "join product_sales p ON c.CustomerID = p.ProductID\n",
        "group by c.Name\n",
        "having SUM(p.Quantity) > 2\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVmTKytSeTJG",
        "outputId": "909d1487-db88-45ef-9b3a-d84784d05559"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+-----------+-------+--------+----------+------------+------+---------+----------+\n",
            "|productid| productname|   category|  price|quantity|  saledate|        Name|Gender|     City|SignupDate|\n",
            "+---------+------------+-----------+-------+--------+----------+------------+------+---------+----------+\n",
            "|      203|    Notebook| Stationery|   50.0|      10|2024-06-03| Priya Singh|Female|Bangalore|2024-05-20|\n",
            "|      201|  Smartphone|Electronics|45000.0|       3|2024-06-01|Alice Sharma|Female|   Mumbai|2024-05-12|\n",
            "|      202|Office Chair|  Furniture| 3000.0|       2|2024-06-02|  Ravi Verma|  Male|    Delhi|2024-05-15|\n",
            "+---------+------------+-----------+-------+--------+----------+------------+------+---------+----------+\n",
            "\n",
            "+------------+-------------+\n",
            "|        Name|TotalQuantity|\n",
            "+------------+-------------+\n",
            "|Alice Sharma|            3|\n",
            "| Priya Singh|           10|\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19. Create a SQL view sales_summary that includes:\n",
        "#ProductName, Price, Quantity, Total = Price * Quantity\n",
        "\n",
        "spark.sql(\"\"\"create or replace view sales_summary as\n",
        "select productname, price, quantity, price * quantity as total\n",
        "from product_sales\n",
        "\"\"\")\n",
        "\n",
        "#20. Query the view for records with\n",
        "#Total > 1000 .\n",
        "spark.sql(\"\"\"\n",
        "select *\n",
        "from sales_summary\n",
        "where total > 1000\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z7WEv3EfLIR",
        "outputId": "c7b8c777-89b9-43b9-8e33-5b4764b32964"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+--------+--------+\n",
            "| productname|  price|quantity|   total|\n",
            "+------------+-------+--------+--------+\n",
            "|  Headphones| 1500.0|       4|  6000.0|\n",
            "|Water Bottle|  250.0|       6|  1500.0|\n",
            "|  Smartphone|45000.0|       3|135000.0|\n",
            "|Office Chair| 3000.0|       2|  6000.0|\n",
            "+------------+-------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Drop the view sales_summary .\n",
        "spark.sql(\"\"\"drop view if exists sales_summary\"\"\")\n",
        "\n",
        "#22. Drop the tables product_sales and customer_details\n",
        "spark.sql(\"drop table product_sales\")\n",
        "spark.sql(\"drop table customer_details\")\n",
        "#23. Drop the database sales_db .\n",
        "spark.sql(\"drop database sales_db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJaf7JZqfZvc",
        "outputId": "14ba1bc1-8236-40e5-b5e9-018219e5d51d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}