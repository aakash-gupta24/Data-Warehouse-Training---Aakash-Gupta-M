{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34005efd-287c-487d-87c5-d68b8e71fbce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=833800893595081#setting/sparkui/0611-043338-tjd8m6e5/driver-8951680990622541171\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c7dfeca1450>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"june19assignment2\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3ca5e69-6c9b-43b2-9352-1cebe49e9467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EnrollID: string (nullable = true)\n",
      " |-- UserID: string (nullable = true)\n",
      " |-- CourseID: string (nullable = true)\n",
      " |-- CourseName: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- EnrollDate: date (nullable = true)\n",
      " |-- CompletionDate: date (nullable = true)\n",
      " |-- ProgressPercent: integer (nullable = true)\n",
      " |-- Rating: integer (nullable = true)\n",
      "\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+\n",
      "\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|             0|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|             0|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingestion & Time Fields\n",
    "# Load into PySpark with inferred schema\n",
    "spark.conf.set(\"fs.azure.account.key.hestore.blob.core.windows.net\",\"---------AccessKeyyy----------\")\n",
    "\n",
    "course_enrollments=spark.read.csv(\"wasbs://june19assignment2@hestore.blob.core.windows.net/course_enrollments.csv\",header=True,inferSchema=True)\n",
    "\n",
    "course_enrollments.printSchema()\n",
    "course_enrollments.show()\n",
    "# Convert EnrollDate and CompletionDate to date type\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col,datediff,to_date\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "course_enrollments=course_enrollments.withColumn(\"EnrollDate\",to_date(col(\"EnrollDate\"),\"MM-dd-yyyy\"))\n",
    "# Add DaysToComplete column if completed\n",
    "course_enrollments = course_enrollments.withColumn(\"DaysToComplete\",when(col(\"ProgressPercent\") == 100, datediff(col(\"CompletionDate\"), col(\"EnrollDate\"))).otherwise(0))\n",
    "course_enrollments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9845bbb-ec76-47c1-8ea9-95f02b521125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|UserID|CourseCount|\n",
      "+------+-----------+\n",
      "|  U004|          1|\n",
      "|  U002|          1|\n",
      "|  U003|          1|\n",
      "|  U001|          2|\n",
      "+------+-----------+\n",
      "\n",
      "+------+------------------+\n",
      "|UserID|AvgProgressPercent|\n",
      "+------+------------------+\n",
      "|  U004|             100.0|\n",
      "|  U002|              45.0|\n",
      "|  U003|             100.0|\n",
      "|  U001|              65.0|\n",
      "+------+------------------+\n",
      "\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|        Yes|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|             0|         No|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|             0|         No|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|        Yes|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|        Yes|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User Learning Path Progress\n",
    "# Group by UserID : count of courses enrolled\n",
    "course_enrollments.groupBy(\"UserID\").agg(count(\"*\").alias(\"CourseCount\")).show()\n",
    "# Avg progress % across all enrollments\n",
    "course_enrollments.groupBy(\"UserID\").agg(avg(\"ProgressPercent\").alias(\"AvgProgressPercent\")).show()\n",
    "# Flag IsCompleted = ProgressPercent = 100\n",
    "course_enrollments=course_enrollments.withColumn(\"IsCompleted\",when(col(\"ProgressPercent\")==100,\"Yes\").otherwise(\"No\"))\n",
    "course_enrollments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f584e6a-d150-49e5-8c95-d20991939b13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|Score|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|        Yes|  400|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|             0|         No| NULL|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|             0|         No| NULL|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|        Yes|  500|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|        Yes|  400|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Engagement Scoring\n",
    "# Create a score: ProgressPercent * Rating (if not null)\n",
    "course_enrollments=course_enrollments.withColumn(\"Score\",col(\"ProgressPercent\")*col(\"Rating\"))\n",
    "# Replace null Rating with 0 before computing\n",
    "course_enrollments=course_enrollments.fillna(0,['Rating'])\n",
    "course_enrollments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15f68b6-1bbb-43df-b6a2-e87729ab045d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identify Drop-offs\n",
    "# Filter all records with ProgressPercent < 50 and CompletionDate is null\n",
    "dropouts=course_enrollments.filter((col(\"ProgressPercent\")<50) & (col(\"CompletionDate\").isNull()))\n",
    "# Create a view called Dropouts\n",
    "dropouts.createOrReplaceTempView(\"Dropouts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfbacf46-bc82-4fb6-8ca6-d6bc44f9157d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|   Instructor|AvgProgressPercent|\n",
      "+-------------+------------------+\n",
      "|  Zoya Sheikh|             100.0|\n",
      "|   Sana Gupta|              45.0|\n",
      "| Ibrahim Khan|              30.0|\n",
      "|Abdullah Khan|             100.0|\n",
      "+-------------+------------------+\n",
      "\n",
      "+-------------+-----------+\n",
      "|   Instructor|CourseCount|\n",
      "+-------------+-----------+\n",
      "|Abdullah Khan|          2|\n",
      "|   Sana Gupta|          1|\n",
      "|  Zoya Sheikh|          1|\n",
      "| Ibrahim Khan|          1|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joins with Metadata\n",
    "# Create course_catalog.csv :\n",
    "# CourseID,Instructor,DurationHours,Level\n",
    "# C001,Abdullah Khan,8,Beginner\n",
    "# C002,Sana Gupta,5,Beginner\n",
    "# C003,Ibrahim Khan,10,Intermediate\n",
    "# C004,Zoya Sheikh,6,Beginner\n",
    "course_catalog=spark.read.csv(\"wasbs://june19assignment2@hestore.blob.core.windows.net/course_catalog.csv\",header=True,inferSchema=True)\n",
    "# Join to find average progress per instructor\n",
    "course_enrollments.join(course_catalog,[\"CourseID\"]).groupBy(\"Instructor\").agg(avg(\"ProgressPercent\").alias(\"AvgProgressPercent\")).show()\n",
    "# Show who teaches the most enrolled course\n",
    "course_enrollments.join(course_catalog,[\"CourseID\"]).groupBy(\"Instructor\").agg(count(\"CourseID\").alias(\"CourseCount\")).orderBy(col(\"CourseCount\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71e3828f-4989-4e28-872a-ee3284345518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|                2|\n",
      "+-----------------+\n",
      "\n",
      "+-----------------+\n",
      "|num_affected_rows|\n",
      "+-----------------+\n",
      "|                0|\n",
      "+-----------------+\n",
      "\n",
      "+-------+-------------------+----------------+--------------------+--------------------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|          userId|            userName|           operation| operationParameters| job|          notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+----------------+--------------------+--------------------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|      8|2025-06-19 06:29:37|8835572673210010|azuser3544_mml.lo...|            OPTIMIZE|{predicate -> [],...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          6|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      7|2025-06-19 06:29:36|8835572673210010|azuser3544_mml.lo...|              DELETE|{predicate -> [\"(...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          6|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      6|2025-06-19 06:29:34|8835572673210010|azuser3544_mml.lo...|              UPDATE|{predicate -> [\"(...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          5|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      5|2025-06-19 06:29:31|8835572673210010|azuser3544_mml.lo...|CREATE OR REPLACE...|{partitionBy -> [...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          4|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|      4|2025-06-19 06:25:52|8835572673210010|azuser3544_mml.lo...|            OPTIMIZE|{predicate -> [],...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          2|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      3|2025-06-19 06:25:49|8835572673210010|azuser3544_mml.lo...|              DELETE|{predicate -> [\"(...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          2|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      2|2025-06-19 06:25:47|8835572673210010|azuser3544_mml.lo...|              UPDATE|{predicate -> [\"(...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          1|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      1|2025-06-19 06:25:40|8835572673210010|azuser3544_mml.lo...|CREATE OR REPLACE...|{partitionBy -> [...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|          0|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "|      0|2025-06-19 06:25:27|8835572673210010|azuser3544_mml.lo...|CREATE OR REPLACE...|{partitionBy -> [...|NULL|{3551558877685490}|0611-043338-tjd8m6e5|       NULL|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "+-------+-------------------+----------------+--------------------+--------------------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delta Lake Practice\n",
    "# Save as Delta Table enrollments_delta\n",
    "course_enrollments.write.mode('overwrite').format(\"delta\").saveAsTable(\"enrollments_delta\")\n",
    "# Apply:\n",
    "# Update: Set all ratings to 5 where Course = 'Python Basics'\n",
    "# Delete: All rows where ProgressPercent = 0\n",
    "# Show DESCRIBE HISTORY\n",
    "spark.sql(\"UPDATE enrollments_delta SET Rating=5 WHERE CourseName='Python Basics'\").show()\n",
    "spark.sql(\"DELETE FROM enrollments_delta WHERE ProgressPercent=0\").show()\n",
    "spark.sql(\"DESCRIBE HISTORY enrollments_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae0460c4-393f-46b3-b2b5-3da0b475bbf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+----+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|Score|rank|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+----+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|        Yes|  400|   1|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|             0|         No| NULL|   2|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|             0|         No| NULL|   1|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|        Yes|  500|   1|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|        Yes|  400|   1|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+----+\n",
      "\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+---------------+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|Score|    next_course|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+---------------+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|        Yes|  400|ML with PySpark|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|             0|         No| NULL|           NULL|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|             0|         No| NULL|           NULL|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|        Yes|  500|           NULL|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|        Yes|  400|           NULL|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Window Functions\n",
    "# Use dense_rank() to rank courses by number of enrollments\n",
    "from pyspark.sql.window import Window\n",
    "windowSpec = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
    "course_enrollments.withColumn(\"rank\",dense_rank().over(windowSpec)).show()\n",
    "# lead() to find next course by each user (sorted by EnrollDate)\n",
    "from pyspark.sql.window import Window\n",
    "windowSpec = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
    "course_enrollments.withColumn(\"next_course\",lead(\"CourseName\",1).over(windowSpec)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a8656b-827c-47af-938e-58671ef8855e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SQL Logic for Dashboard Views\n",
    "# Create views:\n",
    "# daily_enrollments\n",
    "# category_performance (avg rating by category)\n",
    "# top_3_courses\n",
    "daily_enrollments=spark.sql(\"SELECT date_format(EnrollDate,'yyyy-MM-dd') as Date,COUNT(*) as DailyEnrollments FROM enrollments_delta GROUP BY Date\")\n",
    "\n",
    "daily_enrollments.createOrReplaceTempView(\"daily_enrollments\")\n",
    "\n",
    "category_performance=spark.sql(\"SELECT Category,AVG(Rating) as AvgRating FROM enrollments_delta GROUP BY Category\")\n",
    "\n",
    "category_performance.createOrReplaceTempView(\"category_performance\")\n",
    "\n",
    "top_3_courses=spark.sql(\"SELECT CourseName,AVG(Rating) as AvgRating FROM enrollments_delta GROUP BY CourseName ORDER BY AvgRating DESC LIMIT 3\")\n",
    "\n",
    "top_3_courses.createOrReplaceTempView(\"top_3_courses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ee97c86-846a-408b-98f5-04d5a9c4a3f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|Score|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|        Yes|  400|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|             0|         No| NULL|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|             0|         No| NULL|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|        Yes|  500|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|        Yes|  400|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|Score|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     5|             9|        Yes|  400|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|        Yes|  500|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|             0|         No| NULL|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|             0|         No| NULL|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|        Yes|  400|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Travel\n",
    "# View previous version before update/delete\n",
    "spark.sql(\"SELECT * FROM enrollments_delta VERSION AS OF 0\").show()\n",
    "# Use VERSION AS OF and TIMESTAMP AS OF\n",
    "df_time = spark.read.format(\"delta\").option(\"timestampAsOf\", \"2025-06-19 06:25:52\").table(\"enrollments_delta\")\n",
    "\n",
    "df_time.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5e24099-844d-4fd9-8bf7-7b176b3c4207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+---------+-----------+\n",
      "|       CourseName|TotalEnrollments|AvgRating|AvgProgress|\n",
      "+-----------------+----------------+---------+-----------+\n",
      "|Digital Marketing|               1|      4.0|      100.0|\n",
      "|    Python Basics|               2|      5.0|      100.0|\n",
      "|Excel for Finance|               1|      0.0|       45.0|\n",
      "|  ML with PySpark|               1|      0.0|       30.0|\n",
      "+-----------------+----------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export Reporting\n",
    "# Write to JSON, partitioned by Category\n",
    "course_enrollments.write.partitionBy(\"Category\").mode(\"overwrite\").format(\"json\").save(\"dbfs:/FileStore/tables/assignment2/json\")\n",
    "# Create summary DataFrame:\n",
    "# CourseName, TotalEnrollments, AvgRating, AvgProgress\n",
    "summary=spark.sql(\"SELECT CourseName, COUNT(*) as TotalEnrollments, AVG(Rating) as AvgRating, AVG(ProgressPercent) as AvgProgress FROM enrollments_delta GROUP BY CourseName\")\n",
    "summary.show()\n",
    "# Save as Parquet\n",
    "summary.write.mode(\"overwrite\").format(\"parquet\").save(\"dbfs:/FileStore/tables/assignment2/parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "june19assignment2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
