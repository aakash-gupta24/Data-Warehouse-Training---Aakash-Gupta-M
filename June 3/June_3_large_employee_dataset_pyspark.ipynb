{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZUAuUomOiO3",
        "outputId": "54f6f65f-9324-4b20-efbc-030038ba646d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName(\"Colab PySpark Setup\").getOrCreate()\n",
        "\n",
        "spark\n",
        "\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "from pyspark.sql.functions import year\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#read csv\n",
        "sales_df=spark.read.csv('/content/drive/MyDrive/large_employee_dataset.csv',header=True,inferSchema=True)\n",
        "\n",
        "#1.show top 10 rows\n",
        "sales_df.show(10)\n",
        "\n",
        "#2.count total no of employees(records)\n",
        "sales_df.count()\n",
        "\n",
        "#3.display unique department\n",
        "sales_df.select(\"Department\").distinct().show()\n",
        "\n",
        "#4. Filter all employees in the \"IT\" department.\n",
        "sales_df.filter(sales_df[\"Department\"]==\"IT\").show()\n",
        "\n",
        "#5. Show employees aged between 30 and 40.\n",
        "sales_df.filter((sales_df[\"Age\"] > 30) & (sales_df[\"Age\"] < 40)).show()\n",
        "\n",
        "#6. Sort employees by Salary in descending order.\n",
        "sales_df.orderBy(sales_df[\"Salary\"].desc()).show()\n",
        "\n",
        "#7. Get the average salary by department.\n",
        "sales_df.groupBy(\"Department\").avg(\"Salary\").show()\n",
        "\n",
        "#8. Count of employees by Status.\n",
        "sales_df.groupBy(\"Status\").count().show()\n",
        "\n",
        "#9. Highest salary in each city.\n",
        "sales_df.groupBy(\"City\").max(\"Salary\").show()\n",
        "\n",
        "#10. Total number of employees who joined each year.\n",
        "sales_df.groupBy(year(\"JoiningDate\")).count().show()\n",
        "\n",
        "#11. Department-wise count of employees who are currently \"Active\".\n",
        "sales_df.filter(sales_df[\"Status\"]==\"Active\").groupBy(\"Department\").count().show()\n",
        "\n",
        "#12. Average age of employees per department.\n",
        "sales_df.groupBy(\"Department\").avg(\"Age\").show()\n",
        "\n",
        "#13. Create another dataset with City and Region , and join it.\n",
        "city_df=spark.read.csv('/content/drive/MyDrive/location.csv',header=True,inferSchema=True)\n",
        "sales_df=sales_df.join(city_df,sales_df[\"City\"]==city_df[\"City\"],\"inner\")\n",
        "sales_df.show()\n",
        "\n",
        "#14. Group salaries by Region after the join.\n",
        "sales_df.groupBy(\"Region\").sum(\"Salary\").show()\n",
        "\n",
        "#15. Calculate years of experience for each employee (current date - JoiningDate).\n",
        "from pyspark.sql.functions import current_date, datediff, col\n",
        "sales_df = sales_df.withColumn(\"Experience\", datediff(current_date(), col(\"JoiningDate\")) / 365)\n",
        "sales_df.show()\n",
        "\n",
        "#16. List all employees with more than 5 years of experience.\n",
        "sales_df.filter(sales_df[\"Experience\"] > 5).show()\n",
        "\n"
      ]
    }
  ]
}